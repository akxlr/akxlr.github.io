---
layout: post
title:  "Contents"
main-title: "Contents"
---


Acknowledgements 

Abstract



1	Introduction

1.1	The inference problem

1.2	Contribution

1.3	Thesis structure 

1.4	Notation



2	Probabilistic graphical models	

2.1	Background theory 

2.2	Directed models 

2.3	Undirected models 

2.3.1	Ising models and the exponential family

2.3.2	Converting from Bayesian networks to MRFs

2.4	Factor graphs 



3	Exact inference	

3.1	Elimination algorithm   

3.1.1	Elimination order  

3.2	Belief propagation on trees

3.2.1	Implementation   

3.3	Junction tree algorithm 

3.3.1	Building the junction tree

3.3.2	Junction tree inference 



4	Approximate inference

4.1	Loopy belief propagation	 

4.2	Mean-field variational inference  

4.3	Sampling

4.3.1	Markov-chain Monte Carlo



5	Low-rank tensor propagation	

5.1	Tensor rank decomposition  

5.1.1	Existence and uniqueness  

5.1.2	Computation using ALS  

5.1.3	Decomposition for Ising models  



5.1.4	Data structure  

5.2	Operations using decomposed functions 

5.2.1	Marginalisation  

5.2.2	Multiplication   

5.3	Low-rank tensor propagation  

5.4	Analysis   

5.4.1	Setup   

5.4.2	Consistency of tensor propagation 

5.4.3	Multiplicative bound  

5.5	Reweighting of decomposed functions  

5.5.1	Max-norm reweighting	  

5.5.2	Minimum variance reweighting  

5.6	Related work  

5.6.1	Message passing using structured approximations

5.6.2	Particle-based approximations  	

5.6.3	Tensor rank decomposition   



6	Experiments

6.1	Experimental setup

6.2	Ising models	

6.2.1	Performance vs sample size K	

6.2.2	Performance vs problem difficulty	

6.2.3	Distribution of estimated marginals	

6.2.4	Effect of sampling threshold H	

6.3	Random graphs	

6.3.1	Performance vs sample size K	

6.3.2	Performance vs problem difficulty

6.4	Running time	

6.5	Summary	

7	Conclusion and future work	

7.1	Conclusion	

7.2	Future work	

A Index of notation

Bibliography

