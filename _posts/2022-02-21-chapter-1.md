---
layout: post
title:  "Chapter 1"
---

# Probabilistic graphical models {#cha:pgms}

A probabilistic graphical model (PGM) represents a joint probability
distribution $p(\sublist{x}{\mathcal{D}})$ as a directed or undirected
graph. Generally, vertices in the graph represent random variables or
groups of random variables and the edge topology encodes conditional
independence relationships between these variables. Representing
probability distributions in this manner has several advantages. It
provides an intuitive visualisation of the structure of the distribution
and the conditional independence properties among its variables, and
provides a simple means of encoding domain specific knowledge about
causal relationships by adding or removing edges. It allows storage of
large probability distributions that do not otherwise have a convenient
parametric form. Most importantly, algorithms for inference and learning
can operate directly on the graph and exploit its structure for
efficiency [@koller09].

[@jordan2003introduction] refers to graphical models as "probabilistic
databases" that can answer queries regarding the probability of random
variables or sets of variables taking certain values. The canonical
query that we consider in this thesis is univariate *marginalisation*:
given a joint distribution $p(\sublist{x}{\mathcal{D}})$ and optionally
some evidence in the form of $M$ variable assignments
$\{X_i=x_i\}_{i=1}^M$, what is the marginal distribution $p(x_j)$ for a
particular variable $X_j$? We define this problem more concretely
below.[^1] We can consider variants of this task, e.g. marginalisation
over a set of variables instead of a single variable, finding the
assignment of $X_j$ with the highest probability, or finding the
expected value of a set of variables; many of the thereoretical results
in this thesis that pertain to marginalisation also apply to these
related problems but we do not discuss these specifically.

The following is a simple example to motivate the efficiency gains
possible by storing probability distributions in structured form.

::: example
[]{#ex:motivation label="ex:motivation"}

Let $X$, $Y$ and $Z$ be binary random variables with joint distribution
given in table [1.2](#tab:ex1joint){reference-type="ref"
reference="tab:ex1joint"}.

::: {#tab:ex1joint}
   **$x$**   **$y$**   **$z$**   $p(x,y,z)$
  --------- --------- --------- ------------
    **0**     **0**     **0**       0.01
    **0**     **0**     **1**       0.09
    **0**     **1**     **0**       0.03
    **0**     **1**     **1**       0.27
    **1**     **0**     **0**       0.02
    **1**     **0**     **1**       0.18
    **1**     **1**     **0**       0.04
    **1**     **1**     **1**       0.36

  : $p(z)$
:::

::: tabular
\*4c\| &\
& & **0** & **1**\
\*Y & **0** & $0.1$ & $0.3$\
& **1** & $0.2$ & $0.4$\
:::

::: {#tab:ex1joint}
   **0**   **1**
  ------- -------
    0.1     0.9

  : $p(z)$
:::

Storing $p(x,y,z)$ in this form requires storage of $2^3=8$ separate
values. Suppose we wish to compute the marginal probability $P(X=0)$. A
naı̈ve computation of $p(x) = \sum_y \sum_z p(x,y,z)$ yields
$$P(X=0) = 0.01+0.09+0.03+0.27=0.4$$ which requires summing over all
$2^2$ configurations of the other variables. Suppose now that we know
the distribution factorises as $p(x,y,z) = p(x,y)p(z)$ as shown. We can
now store the same distribution with only $2^2 + 2 = 6$ parameters, and
the marginal probability $P(X=0)$ can be obtained faster by using the
factorisation: $$\begin{aligned}
p(x) &= \sum_y \sum_z p(x,y,z) \\
     &= \sum_y \sum_z p(x,y) p(z) \\
     &= \sum_y p(x,y) \sum_z p(z) \\
     \implies P(X=0) &= 0.1 + 0.3 = 0.4.\end{aligned}$$ 

When working with models with thousands of variables, efficiency gains such as these
become substantial.
:::

## Background theory {#sec:background}

We begin by reviewing some basic definitions necessary for the remainder
of this paper.

::: definition

[]{#def:marg label="def:marg"} Let $p(\sublist{x}{\mathcal{D}})$ be a
probability distribution over discrete random variables
$\sublist{X}{\mathcal{D}}$. The *marginal distribution* of a variable
$X_i$, denoted $p(x_i)$, is given by 

$$\begin{aligned}
p(x_i) &= \sum_{\mathbf{x}_{-i}} p(\sublist{x}{\mathcal{D}}) \nonumber \\
&= \sum_{x_1}\sum_{x_2}\cdots\sum_{x_{i-1}}\sum_{x_{i+1}}\cdots\sum_{x_\mathcal{D}} p(\sublist{x}{\mathcal{D}}) \label{eq:marg}
\end{aligned} $$ 

where $\mathbf{x}\_{-i}$ denotes the set of all $\sublist{x}{\mathcal{D}}$ excluding $x_i$.
The marginal distribution over a non-singleton set of variables $\mathbf{X}\_S$ is defined similarly:
$p(\mathbf{x}\_S) = \sum_{\mathbf{x}\_{-S}} p(\sublist{x}{\mathcal{D}})$.

:::

The process of computing the marginal distribution for a given variable
or set of variables is called *marginalisation*. Marginalisation over
large probability distributions is hard, because in general it requires
visiting the exponential number of variable configurations in the joint
distribution. More precisely, a tabular representation of
$p(\sublist{x}{\mathcal{D}})$ contains number of entries equal to the
product of the domain sizes of each variable, and to perform the
summation ([\[eq:marg\]](#eq:marg){reference-type="ref"
reference="eq:marg"}) by brute force we must visit all of these. In this
thesis, we also use the term marginalisation to describe the analogous
operation to ([\[eq:marg\]](#eq:marg){reference-type="ref"
reference="eq:marg"}) when $p$ is an arbitrary function (that is, not a
normalised probability distribution).

::: definition
Let $X$, $Y$ and $Z$ be discrete random variables. $X$ is *independent*
of $Y$, denoted $X \ci Y$, if $p(x,y) = p(x)p(y)$ for all $x,y$.
:::

::: definition
Let $X$, $Y$ and $Z$ be discrete random variables. $X$ is *conditionally
independent* of $Y$ given $Z$, denoted $X \ci Y \given Z$, if
$p(x,y\given z) = p(x\given z)p(y\given z)$ for all $x, y, z$.
:::

## Directed models {#sec:directed}

The key motivation for graphical models is to exploit structure present
in a distribution to perform efficient computations. This structure can
be examined in two different ways, which turn out to be equivalent. A
PGM can be seen as encoding

-   the conditional independence properties present in the joint
    distribution; or

-   how the joint distribution factorises.

We begin by describing these properties for directed models.

::: definition
A *Bayesian network* or *directed graphical model* is a directed acyclic
graph $G$ that represents a probability distribution
$p(\sublist{x}{\mathcal{D}})$. $G$ has $\mathcal{D}$ nodes corresponding
to variables $\sublist{X}{\mathcal{D}}$ respectively, and contains edges
that encode the set of conditional independence assumptions
$$\begin{aligned}
    X_i \ci \nd(X_i) \given \pa(X_i)\end{aligned}$$ where $\nd(X_i)$ is
the set of nodes in $G$ that are not descendants of $X_i$ and $\pa(X_i)$
is the set of parents of $X_i$ in $G$. Equivalently, $G$ encodes the
factorisation $$\begin{aligned}
    P(\sublist{x}{\mathcal{D}}) = \prod_{i=1}^\mathcal{D} p(x_i \given \pa(x_i)) \label{eq:bn_fact}\end{aligned}$$
where the factors $p(x_i \given \pa(x_i))$ are called *conditional
probability distributions* (CPDs) or, in the discrete case, *conditional
probability tables* (CPTs) [@koller09].
:::

The former property states that each variable is conditionally
independent of its non-descendents given its direct parents. The latter
gives us an easy way of reading the factorisation of the joint
distribution directly from the graph: for each node $X_i$, the joint
distribution contains a factor $p(x_i \given \pa(x_i))$. These
properties are equivalent: the set of distributions that factorises
according to a given Bayesian network $G$ is equal to the set of
distributions that satisfy the conditional independence relationships
implied by $G$ [@bis06; @koller09].

Bayesian networks provide a natural way of encoding domain-specific
knowledge and intuition about variable relationships. The CPDs can be
produced from expert knowledge or learned from data.

## Undirected models {#sec:undirected}

In a similar manner, we can use undirected graphs to model multivariate
distributions. So-called *Markov random fields* (MRFs) are widely used
in computer vision, natural language processing and other related
fields.

::: definition
[]{#def:mrf label="def:mrf"}[@dom14] Let $G$ be an undirected graph with
$\mathcal{D}$ nodes representing random variables
$\sublist{X}{\mathcal{D}}$ respectively. A probability distribution
$p(\sublist{x}{\mathcal{D}})$ is a *Markov random field* with respect to
$G$ if, for any disjoint subsets $A$, $B$ and $C$ of nodes in $G$,
$$\begin{aligned}
\label{eq:mrf_ci}
    \mathbf{X}_A \ci \mathbf{X}_B \given \mathbf{X}_C \iff \textrm{$C$ separates $A$ from $B$ in $G$}.\end{aligned}$$
:::

As with Bayesian networks, MRFs have a convenient interpretation in
terms of factorisation of the joint distribution. Any positive[^2] MRF
over $G$ for which the conditional independence properties in
([\[eq:mrf_ci\]](#eq:mrf_ci){reference-type="ref"
reference="eq:mrf_ci"}) hold will admit a factorisation
$$\begin{aligned}
\label{eq:mrf_fact}
    p(\sublist{x}{\mathcal{D}}) = \frac{1}{Z} \prod_{c\in\cl{G}} \phi_c(\mathbf{x}_c), \quad Z = \sum_{\mathbf{x}}\prod_{c\in\cl{G}} \phi_c(\mathbf{x}_c)\end{aligned}$$
where $\cl{G}$ denotes the set of maximal cliques in $G$, and the
constant $Z$, often called the *partition function*, ensures
normalisation. The factors $\phi_c$ are called *clique potentials*, and
by definition satisfy $\phi_c(\mathbf{x}_c) \geq 0$. In words,
([\[eq:mrf_fact\]](#eq:mrf_fact){reference-type="ref"
reference="eq:mrf_fact"}) says that the joint distribution has a factor
for each max-clique in $G$.

It is important to note that the clique potentials in an MRF are not
necessarily probability distributions, because they need not satisfy the
normalisation constraint $\sum_{\mathbf{x}_c} \phi_c(\mathbf{x}_c)=1$.
This property means Bayesian networks and MRFs behave quite differently.
MRFs are useful for modeling relationships between variables where the
directionality of the relationship is unclear [@koller09], and often
provide a more convenient framework for reasoning about inference tasks,
as in the junction tree algorithm described in Section
[\[sec:jt\]](#sec:jt){reference-type="ref" reference="sec:jt"}. The lack
of explicit normalisation is often powerful but comes at a cost --
calculating $Z$ requires a sum over exponentially many states in the
same manner as marginalisation, and thus is generally intractable. Some
tasks do not require explicit knowledge of $Z$, but for learning it is
often required and must be estimated.

### Ising models and the exponential family

Ising models are a particular type of MRF that we use as our main test
case in this thesis. We introduce these in the context of *exponential
families*.

::: definition
An *exponential family* [@pit36] is a set of distributions of the form
$$\begin{aligned}
        p(\mathbf{x}) = \exp \left( \bm{\theta}^\T \mathbf{f}(\mathbf{x}) -A(\bm{\theta}) \right)
    \end{aligned}$$ where $\bm{\theta}$ is a vector of parameters called
*natural parameters*, $\mathbf{f}(\mathbf{x})$ is any function of
$\mathbf{x}$ and
$A(\bm{\theta})=\log \sum_{\mathbf{x}} \exp ( \bm{\theta}^\T \mathbf{f}(\mathbf{x}))$
ensures normalisation.
:::

Several important distributions belong to exponential families,
including Gaussian, Bernoulli, Dirichlet, beta and others. Exponential
families are closely related to MRFs: [@koller09] show how any MRF can
trivially be expressed in log-linear form
$$p(\sublist{x}{\mathcal{D}}) \propto \sum_{c=1}^{N_c} \theta_c\;f_c(\mathbf{x}_c)$$
which is an exponential family.

::: definition
A (2D) *Ising model* is an exponential family MRF with pairwise
potentials arranged in an $N\times N$ grid as in figure
[\[fig:ising\]](#fig:ising){reference-type="ref" reference="fig:ising"}.
Each variable $X_i$ takes either the value $1$ or $-1$, and edge
potentials are given by
$$\phi_{ij}(x_i,x_j) = \exp (w_{ij}x_i x_j),\quad w_{ij}\in\mathbb{R}.$$
Each variable also has a bias factor
$$\phi_i(x_i) = \exp (b_i x_i),\quad b_i\in\mathbb{R},$$ giving the
joint distribution $$\begin{aligned}
        p(\sublist{x}{\mathcal{D}}) = \frac{1}{Z} \exp \left( \sum_{(i,j)}w_{ij}x_i x_j + \sum_i b_i x_i \right)
    \end{aligned}$$ where the first sum runs over all edges in the graph
and the second over all nodes.
:::

Ising models [@len20; @isi25] are commonly used as test cases in PGM
literature. They originate from statistical physics where they were
first introduced to study interactions between atoms. An Ising model is
parametrised by a set of *interaction strengths* $\{w_{ij}\}$ and
*external fields* $\{b_i\}$. The interaction strengths describe the
model's preference for neighbouring variables to match: if $w_{ij}>0$,
the effect is to assign high probability if variables $X_i$ and $X_j$
are equal, and if $w_{ij}<0$ the model prefers $X_i$ and $X_j$ to take
opposite values. The external fields allow a bias toward $1$ or $-1$ for
each variable. Inference in Ising models is computationally hard as the
size increases, making them useful test cases for approximate inference
algorithms. Generalisations of Ising models are also used in computer
vision applications.

### Converting from Bayesian networks to MRFs

As stated above, undirected models are often more convenient for
reasoning about certain algorithms (including those in the remaining
chapters). Thus, we often must convert Bayesian networks to MRFs. This
is achieved using a process known as *moralisation*. For each node in
the Bayesian network, we connect all pairs of its parents together with
undirected edges. Then, we drop the directionality on the remaining
edges to give an MRF. Finally, the CPDs from the Bayesian networks are
multiplied onto the relevant cliques of the MRF to give the clique
potentials. Due to the local normalisation of the CPDs, the partition
function is $Z=1$. Note that in general, this process loses some of the
conditional independence properties present in the original Bayesian
network [@bis06].

## Factor graphs {#sec:factor}

We have stated that both Bayesian networks and MRFs describe how a joint
distribution factorises. *Factor graphs* represent a distribution by
making this factorisation explicit, and can describe more fine-grained
factorisation properties.

::: definition
A *factor graph* $G$ is a bipartite graph containing two types of nodes:
*variable nodes* which represent random variables, and *factor nodes*
which represent factors. Each factor $f_i$ is connected to the variables
of which the factor is a function, and there are no other edges in $G$.
$G$ represents the joint distribution $$\begin{aligned}
    p(\sublist{x}{\mathcal{D}}) = \frac{1}{Z} \prod_i f_i(\mathbf{x}_i), \quad Z = \sum_{\mathbf{x}}\prod_i f_i(\mathbf{x}_i)\end{aligned}$$
where $i$ runs over all factor nodes and $\mathbf{x}_i=\scope{(f_i)}$ is
the set of variables in factor $f_i$.
:::

Because they explicitly represent the factorisation, factor graphs are
capable of encoding additional structure compared to Bayesian networks
and MRFs [@bis06]. They are also useful as a unifying framework to
represent both other types of model. Any Bayesian network or MRF can be
encoded as a factor graph in a straightforward way using the
factorisations ([\[eq:bn_fact\]](#eq:bn_fact){reference-type="ref"
reference="eq:bn_fact"}) and
([\[eq:mrf_fact\]](#eq:mrf_fact){reference-type="ref"
reference="eq:mrf_fact"}). In the case of Bayesian networks, the factor
nodes represent conditional probability distributions and the
normalisation constant $Z$ is $1$. For MRFs, the factor nodes represent
max-cliques.

[^1]: We do not further discuss inference with evidence specifically,
    but all of the algorithms we discuss apply equally to this case.

[^2]: The existence of the factorisation
    ([\[eq:mrf_fact\]](#eq:mrf_fact){reference-type="ref"
    reference="eq:mrf_fact"}) is provided by the *Hammersley-Clifford
    theorem* [@besag1974spatial], and notably is only guaranteed if
    $p(\sublist{x}{\mathcal{D}})>0$. The reverse, however, is always
    true: any distribution that factorises according to
    ([\[eq:mrf_fact\]](#eq:mrf_fact){reference-type="ref"
    reference="eq:mrf_fact"}) over a graph $G$ satisfies the conditional
    independence properties in definition
    [\[def:mrf\]](#def:mrf){reference-type="ref" reference="def:mrf"}.
